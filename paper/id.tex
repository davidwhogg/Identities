\documentclass[12pt]{article}

\addtolength{\textheight}{1.5in}
\addtolength{\headheight}{-0.75in}
\sloppy\sloppypar\raggedbottom\frenchspacing

\begin{document}

\section*{Matrix and Gaussian Identities}

{\raggedright
\textbf{Sam~Roweis}%
\footnote{Deceased.
Formerly at the \textsl{Department of Computer Science, New York University}.},
\textbf{David~W.~Hogg}%
\footnote{\textsl{Center for Cosmology and Particle Physics, Department of Physics, New York University}; and the \textsl{Flatiron Institute, a Division of the Simons Foundation}.},
\textbf{Dustin~Lang}%
\footnote{\textsl{Perimeter Institute}.},
\& \textbf{Boris~Leistedt}%
\footnote{\textsl{Center for Cosmology and Particle Physics, Department of Physics, New York University}.}
}

\paragraph{Abstract:}
Across all areas of data analysis, probability, statistics, machine learning, and
indeed a far larger set of domains, the linear algebra of rectangular matrices
is core. And nowhere is this more true than in problems that involve Gaussians (normal
distributions), which appear explicitly or implicitly in many different methods.
Here we assemble a set of mathematical identities and relationships involving
matrices and their derivatives, and another involving Gaussians.
The set is not exhaustive, but concentrates on the identities most valuable
for the appearance of matrices and Gaussians in machine-learning and data-analysis contexts.
This paper expands and adds context to some crib sheets that have been
available on the internet for years now.

\clearpage
\section{Introduction}

Hello World

\end{document}
