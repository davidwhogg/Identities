\documentclass[11pt,reqno,intlimits]{article}

\include{samsetup}

\newcommand{\sm}[1]{[\begin{smallmatrix}#1\end{smallmatrix}]}
\newcommand{\bm}[1]{\begin{bmatrix}#1\end{bmatrix}}
\newcommand{\xx}{{\mathbf x}}
\newcommand{\yy}{{\mathbf y}}
\newcommand{\zz}{{\mathbf z}}
\newcommand{\CC}{{\mathbf C}}
\newcommand{\DD}{{\mathbf D}}
\newcommand{\BB}{{\mathbf B}}
\newcommand{\EE}{{\mathbf E}}
\newcommand{\FF}{{\mathbf F}}
\newcommand{\XX}{{\mathbf X}}
\newcommand{\YY}{{\mathbf Y}}
\newcommand{\VV}{{\mathbf V}}
\newcommand{\UU}{{\mathbf U}}
\renewcommand{\AA}{{\mathbf A}}
\newcommand{\QQ}{{\mathbf Q}}
\newcommand{\RR}{{\mathbf R}}
\newcommand{\TT}{{\mathbf T}}
\newcommand{\ZZ}{{\mathbf 0}}
\newcommand{\II}{{\mathbf I}}
\newcommand{\ee}{{\mathbf e}}
\newcommand{\bb}{{\mathbf b}}
\newcommand{\cc}{{\mathbf c}}
\newcommand{\aaa}{{\mathbf a}}
%\newcommand{\bbb}{{\boldsymbol \beta}}
\newcommand{\mmm}{{\boldsymbol \mu}}
\newcommand{\Lm}{{\boldsymbol \Lambda}}
\newcommand{\Sm}{{\boldsymbol \Sigma}}
\newcommand{\Pv}{{\boldsymbol \pi}_1}
\newcommand{\Pm}{{\boldsymbol \Pi}_1}
\newcommand{\trace}[1]{\text{Tr}\left[ #1 \right]}
\newcommand{\rank}[1]{\text{rank}\left[ #1 \right]}


\begin{document}

\title{matrix and gaussian identities}
\author{sam roweis\thanks{Thanks to Mike Brooks and Zoubin Ghahramani
for contributing identities to these pages.}}
\date{ \hrule
%\begin{center}
%May 1997
%\end{center}
}

\maketitle

{\bf note} that $\aaa$,$\bb$,$\cc$ and $\AA$,$\BB$,$\CC$ 
do not depend on $\XX$,$\YY$,$\xx$,$\yy$ or $z$

\subsection{basic formulae}
\beqa
\AA(\BB + \CC) &= \AA\BB + \AA \CC \\
(\AA + \BB)^T &= \AA^T + \BB^T \\
(\AA\BB)^T &= \BB^T \AA^T \\
 \text{if individual inverses exist} \quad (\AA\BB)^{-1} &= \BB^{-1}\AA^{-1} \\
(\AA^{-1})^T &= (\AA^T)^{-1}
\eeqa

\subsection{trace, determinant and rank}
\beqa
|\AA \BB| &= |\AA| |\BB| \\
|\AA^{-1}| &= \frac{1}{|\AA|} \\
|\AA| &= \prod \text{evals} \\
\trace{\AA} &= \sum \text{evals} \\
\text{if the cyclic products are well defined}, \nonumber \\
\trace{\AA\BB\CC \dots} = \trace{\BB\CC \dots \AA} = 
\trace{\CC \dots \AA\BB} = \dots \\
\rank{\AA} = \rank{\AA^T\AA}  = \rank{\AA\AA^T} \\
\text{condition number} = \gamma = \sqrt{\frac{\text{biggest
eval}}{\text{smallest eval}}}
\eeqa


{\bf derivatives} of scalar forms with respect to scalars, vectors, or
matricies are indexed in the obvious way. similarly, the indexing for
derivatives of vectors and matrices with respect to scalars is
straightforward.

\subsection{derivatives of traces}
\beqa
\frac{\partial \trace{\XX}}{\partial \XX} &= \II \\
\frac{\partial \trace{\XX \AA}}{\partial \XX} =
\frac{\partial \trace{\AA \XX}}{\partial \XX} &= \AA^T\\
\frac{\partial \trace{\XX^T \AA}}{\partial \XX} =
\frac{\partial \trace{\AA \XX^T}}{\partial \XX} &= \AA\\
\frac{\partial \trace{\XX^T\AA \XX}}{\partial \XX} &= (\AA+\AA^T)\XX \\
\frac{\partial \trace{\XX^{-1} \AA}}{\partial \XX} &= 
-\XX^{-1} \AA^T \XX^{-1}
\eeqa


\subsection{derivatives of determinants}
\beqa
\frac{\partial |\AA\XX\BB|}{\partial \XX} = |\AA\XX\BB|(\XX^{-1})^T &=
|\AA\XX\BB|(\XX^T)^{-1}\\
\frac{\partial \ln |\XX|}{\partial \XX} = (\XX^{-1})^T &= (\XX^T)^{-1}\\
\frac{\partial \ln |\XX(z)|}{\partial z} &=
\trace{(\XX^{-1})^T\frac{\partial \XX}{\partial z}} \\
\text{for real, square} \thinspace \AA \quad 
\frac{\partial |\XX^T\AA\XX|}{\partial \XX} &=
|\XX^T\AA\XX|(\AA+\AA^T)\XX(\XX^T\AA\XX)^{-1} 
\eeqa

\subsection{derivatives of scalar forms}
\beqa
\frac{\partial (\aaa^T \xx)}{\partial \xx} = 
\frac{\partial (\xx^T \aaa)}{\partial \xx} &= \aaa \\
\frac{\partial (\xx^T\AA\xx)}{\partial \xx} &= (\AA + \AA^T)\xx \\ 
\frac{\partial (\aaa^T\XX\bb)}{\partial \XX} &= \aaa\bb^T  \\
\frac{\partial (\aaa^T\XX^T\bb)}{\partial \XX} &= \bb\aaa^T  \\
\frac{\partial (\aaa^T\XX\aaa)}{\partial \XX} = 
\frac{\partial (\aaa^T\XX^T\aaa)}{\partial \XX} &= \aaa\aaa^T \\
\frac{\partial (\aaa^T\XX^T\CC\XX\bb)}{\partial \XX} &= 
\CC^T\XX\aaa\bb^T + \CC\XX\bb\aaa^T \\
\frac{\partial \left((\XX\aaa+\bb)^T\CC(\XX\aaa+\bb)\right)}{\partial \XX} &= 
(\CC+\CC^T)(\XX\aaa+\bb)\aaa^T
\eeqa

%d                      -1 dA   
%-- log det A = Trace (A   --), 
%da                        da   


the {\bf derivative} of one vector $\yy$ with respect to
another vector $\xx$ is a matrix whose $(i,j)^{th}$ element is
$\partial y(j)/ \partial x(i)$. such a derivative should be written as
$\partial \yy^T / \partial \xx$
 in which case it is the {\em
Jacobian} matrix of $\yy$ wrt $\xx$. its determinant 
represents the ratio of the hypervolume $d\yy$ to that of
$d\xx$ so that 
$\int f(\yy) d\yy = \int f(\yy(\xx)) |\partial \yy^T /\partial \xx|d\xx$. 
however, the sloppy forms 
$\partial \yy / \partial \xx$,
$\partial \yy^T / \partial \xx^T$ and
$\partial \yy / \partial \xx^T$ are often used for this Jacobain matrix.




\subsection{derivatives of vector/matrix forms}
\beqa
\frac{\partial (\XX^{-1})}{\partial z} &= -
\XX^{-1}  \frac{\partial \XX}{\partial z} \XX^{-1} \\
\frac{\partial (\AA \xx)}{\partial z} &= \AA  
\frac{\partial \xx}{\partial z}\\
\frac{\partial (\XX \YY)}{\partial z} &=
\XX  \frac{\partial \YY}{\partial z} +
\frac{\partial \XX}{\partial z} \YY \\ 
\frac{\partial (\AA \XX \BB)}{\partial z} &= \AA 
\frac{\partial \XX}{\partial z} \BB\\  
\frac{\partial (\xx^T\AA)}{\partial \xx} &= \AA \\ 
\frac{\partial (\xx^T)}{\partial \xx} &= \II \\
\frac{\partial (\xx^T\AA\xx\xx^T)}{\partial \xx} &= 
(\AA+\AA^T)\xx\xx^T+\xx^T\AA\xx\II
\eeqa

\subsection{constrained maximization}
the maximum over $\xx$ of the quadratic form:
\beq
\mmm^T\xx - \frac{1}{2}\xx^T\AA^{-1}\xx
\eeq 
subject to the $J$ conditions $c_j(\xx)=0$  is given by:
\beq
\AA\mmm + \AA\CC\Lm, \qquad \Lm = -4(\CC^T\AA\CC)\CC^T\AA\mmm
\eeq
where the $j$th column of $\CC$ is $\partial c_j(\xx) / \partial \xx$


\subsection{symmetric matrices}
have real eigenvalues, though perhaps not distinct and can always
be diagonalized to the form: 
\beq
\AA = \CC \Lm \CC^T
\eeq
where the columns of $\CC$
are (orthonormal) eigenvectors (\ie $\CC \CC^T = \II$) and the
diagonal of $\Lm$ has the eigenvalues


\subsection{block matrices}
for conformably partitioned block matrices, addition and
multiplication is performed by adding and multiplying blocks in
exactly the same way as scalar elements of regular matrices

\noindent 
however, determinants and inverses of block matrices are very tricky;
for 2 blocks by 2 blocks the results are:
\beqa
\begin{vmatrix}\AA_{11}&\AA_{12}\\ \AA_{21}&\AA_{22}\end{vmatrix} 
&= |\AA_{22}| \cdot |\FF_{11}| = |\AA_{11}| \cdot  |\FF_{22}| \\ 
{\begin{bmatrix}\AA_{11}&\AA_{12}\\ \AA_{21}&\AA_{22}\end{bmatrix}}^{-1} &=
\begin{bmatrix}
\FF_{11}^{-1}&-\AA_{11}^{-1}\AA_{12}\FF_{22}^{-1}\\
-\FF_{22}^{-1}\AA_{21}\AA_{11}^{-1}& \FF_{22}^{-1}
\end{bmatrix} \\
&= \begin{bmatrix} 
\AA_{11}^{-1}+\AA_{11}^{-1} \AA_{12} \FF_{22}^{-1} \AA_{21} \AA_{11}^{-1} & 
-\FF_{11}^{-1} \AA_{12} \AA_{22}^{-1}\\
-\AA_{22}^{-1} \AA_{21} \FF_{11}^{-1} & 
\AA_{22}^{-1}+\AA_{22}^{-1} \AA_{21} \FF_{11}^{-1} \AA_{12} \AA_{22}^{-1}
\end{bmatrix} 
\eeqa

where
\beqa
\FF_{11} = \AA_{11}-\AA_{12}\AA_{22}^{-1}\AA_{21} \\
\FF_{22} = \AA_{22}-\AA_{21}\AA_{11}^{-1}\AA_{12}
\eeqa

for block {\em diagonal} matrices things are much easier:
\beqa
\begin{vmatrix}\AA_{11} & \ZZ \\ \ZZ & \AA_{22}\end{vmatrix} 
&=  |\AA_{11}||\AA_{22}|\\
{\begin{bmatrix}\AA_{11} & \ZZ \\ \ZZ &\AA_{22}\end{bmatrix}}^{-1} &=
\begin{bmatrix}
\AA_{11}^{-1} & \ZZ \\ \ZZ & \AA_{22}^{-1}
\end{bmatrix}
\eeqa

\subsection{matrix inversion lemma}
using the above results for block matrices we can make some
substitutions and get the following important result:

\beq
(\AA + \XX\BB\XX^T)^{-1} = 
\AA^{-1}-\AA^{-1}\XX(\BB^{-1}+\XX^T\AA^{-1}\XX)^{-1}\XX^T\AA^{-1}
\eeq

where $\AA$ and $\BB$ are {\em square} and {\em invertible} matrices
but need not be of the same dimension.
this lemma often
allows a really hard inverse to be converted into an easy inverse. the
most typical example of this is when $\AA$ is large but diagonal, and
$\XX$ has many rows but few columns

\newpage
\subsection{multidimensional gaussian}
a $d$-dimensional multidimensional gaussian (normal) density for $\xx$
is:
\beq
\normal{\mmm}{\Sm} = 
(2\pi)^{-d/2}|\Sm|^{-1/2}
\exp\left[-\frac{1}{2}(\xx-\mmm)^T\Sm^{-1}(\xx-\mmm)\right]
\eeq
it has entropy:
\beq
S = \frac{1}{2}\log_2\left[ (2\pi e)^d|\Sm| \right] \: - \text{const}
\quad \text{bits}
\eeq
% entropy of a gaussian is
% S = k/2 (1+log(2 pi) ) + 1/2 log ( m^2 det A^{-1} ) 
% where k is dimensionality, A is covariance matrix and m is the
% measure on \xx that makes the probability dimensionless
where $\Sm$ is a symmetric postive semi-definite covariance matrix and
the (unfortunate) constant is the log of the units in which $\xx$ is
measured over the ``natural units''

\subsection{linear functions of a normal vector}
no matter how $\xx$ is distributed,
\beqa
\mathrm{E}[\AA\xx+\yy] &= \AA(\mathrm{E}[\xx]) + \yy \\
\mathrm{Covar}[\AA\xx + \yy] &= \AA(\mathrm{Covar}[\xx])\AA^T
\eeqa
in particular this means that for normal distributed quantities:
\beqa
\xx \distrib \normal{\mmm}{\Sm} &\Rightarrow
(\AA\xx + \yy) \distrib \normal{\AA\mmm + \yy}{\AA \Sm \AA^T} \\
\xx \distrib \normal{\mmm}{\Sm} &\Rightarrow
\Sm^{-1/2}(\xx - \mmm) \distrib \normal{\ZZ}{\II} \\
\xx \distrib \normal{\mmm}{\Sm} &\Rightarrow
(\xx - \mmm)^T\Sm^{-1}(\xx - \mmm) \distrib \chi^2_n 
\eeqa

\subsection{marginal and conditional distributions}
let the vector $\zz=[\xx^T \yy^T]^T$ be normally distributed according
to:
\beq
\zz  = \begin{bmatrix}\xx \\ \yy \end{bmatrix}
\distrib \normal{\begin{bmatrix}\aaa \\ \bb \end{bmatrix}}
{\begin{bmatrix}\AA & \CC \\ \CC^T & \BB \end{bmatrix}}
\eeq
where $\CC$ is the (non-symmetric)
cross-covariance matrix between $\xx$ and $\yy$ which has as
many rows as the size of $\xx$ and as many columns as the size of
 $\yy$. then the marginal distributions are:
\beqa
\xx &\distrib \normal{\aaa}{\AA} \\
\yy &\distrib \normal{\bb}{\BB}
\eeqa
and the conditional distributions are:
\beqa
\xx | \yy &\distrib \normal{\aaa + \CC\BB^{-1}(\yy-\bb)}
{\AA - \CC\BB^{-1}\CC^T} \\
\yy | \xx &\distrib \normal{\bb + \CC^T\AA^{-1}(\xx-\aaa)}
{\BB - \CC^T\AA^{-1}\CC}
\eeqa




\end{document}            




  

